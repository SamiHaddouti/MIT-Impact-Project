{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team MSM: Mini-Hackathon for synthesis prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateEmbedding():\n",
    "\n",
    "    def __init__(self, embedding_file: str = \"data/formulas_to_embedding.pkl\") -> None:\n",
    "        with open(embedding_file, \"rb\") as f:\n",
    "            self.formulas_to_embedding = pickle.load(f)\n",
    "    \n",
    "    def get_embedding(self, target_formula: str) -> np.array:\n",
    "        return np.array(self.formulas_to_embedding[target_formula])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv_file: str = \"data/ground_truth_sets.csv\") -> None:\n",
    "\n",
    "        def convert_to_list_of_lists(cell):\n",
    "            return ast.literal_eval(cell)\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file, converters={1: convert_to_list_of_lists})\n",
    "\n",
    "        self.formulas_to_embedding = CandidateEmbedding().formulas_to_embedding\n",
    "\n",
    "        with open(\"data/candidates.json\", \"r\") as f:\n",
    "            self.candidates = json.load(f)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, List[int]]:\n",
    "        target_formula = self.data.iloc[idx, 0]\n",
    "        target_formula = self.formulas_to_embedding[target_formula]\n",
    "        precursor_indexes = []\n",
    "        precursor_formulas = self.data.iloc[idx, 1]\n",
    "        for p in precursor_formulas:\n",
    "             precursor_indexes.append(self.precursor_to_index(p))\n",
    "        return target_formula, precursor_indexes\n",
    "\n",
    "    def precursor_to_index(self, precursor_set: List[str]) -> int:\n",
    "        try:\n",
    "            index = self.candidates.index(precursor_set)\n",
    "        except ValueError:\n",
    "            index = -1  # Return -1 if the precursor_set is not found\n",
    "        return index\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    target_formulas, precursor_indexes = zip(*batch)\n",
    "    \n",
    "    # Convert target formulas to tensors\n",
    "    target_formulas = [torch.tensor(tf, dtype=torch.float32) for tf in target_formulas]\n",
    "    \n",
    "    # Pad precursor indexes to the same length\n",
    "    max_length = max(len(pf) for pf in precursor_indexes)\n",
    "    padded_precursor_indexes = [\n",
    "        torch.tensor(pf + [-1] * (max_length - len(pf)), dtype=torch.long) for pf in precursor_indexes\n",
    "    ]\n",
    "    \n",
    "    return torch.stack(target_formulas), torch.stack(padded_precursor_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "            def __init__(self, json_file: str = \"data/test_targets.json\") -> None:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    self.data = json.load(f)\n",
    "                self.formulas_to_embedding = CandidateEmbedding().formulas_to_embedding\n",
    "            \n",
    "            def __len__(self) -> int:\n",
    "                return len(self.data)\n",
    "            \n",
    "            def __getitem__(self, idx: int) -> np.ndarray:\n",
    "                target_formula = self.data[idx]\n",
    "                target_formula = self.formulas_to_embedding[target_formula]\n",
    "                return target_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisPredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim: int=512, hidden_dim: int=1024, output_dim: int=27106):\n",
    "        super(SynthesisPredictionModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, target_formula: np.ndarray) -> Tensor:\n",
    "        x = F.relu(self.input_layer(target_formula))\n",
    "        x = F.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the last layer: Vector 27106 x 1\n",
    "\n",
    "Target in the ground truth: Sets of materials, have to be translated to [m, n, ...]\n",
    "\n",
    "Test target: Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRankLoss(nn.Module):\n",
    "    def __init__(self, margin: float=10.0):\n",
    "        \"\"\"\n",
    "        Custom loss to ensure the highest logits correspond to the correct indices.\n",
    "        Args:\n",
    "            margin (float): Minimum margin by which correct logits must exceed incorrect logits.\n",
    "        \"\"\"\n",
    "        super(CustomRankLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, logits, padded_correct_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits (torch.Tensor): Model output of shape (batch_size, num_classes).\n",
    "            correct_indices (List[torch.Tensor]): List of tensors where each tensor contains the correct indices for each example in the batch.\n",
    "        Returns:\n",
    "            torch.Tensor: Computed loss.\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        loss = 0.0\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            correct_indices = padded_correct_indices[i]\n",
    "            valid_indices = correct_indices[correct_indices >= 0]\n",
    "            correct_logits = logits[i, valid_indices]  # Logits at correct indices\n",
    "\n",
    "            # Get the logits for all other indices (incorrect logits)\n",
    "            incorrect_logits = logits[i]\n",
    "            incorrect_logits = incorrect_logits[\n",
    "                torch.isin(\n",
    "                    elements=torch.arange(logits.size(1), device=logits.device), \n",
    "                    test_elements=valid_indices, \n",
    "                    invert=True,\n",
    "                    )\n",
    "                ]  # Remove correct indices\n",
    "            \n",
    "            # print(f\"Length of output vector: {len(logits[i])}\")\n",
    "            # print(f\"Length of correct indices: {len(correct_indices)}\")\n",
    "            # print(correct_indices)\n",
    "            # print(f\"Length of valid indices: {len(valid_indices)}\")\n",
    "            # print(valid_indices)\n",
    "            # print(f\"Length of correct logits: {len(correct_logits)}\")\n",
    "            # print(correct_logits)\n",
    "            # print(f\"Length of incorrect logits: {len(incorrect_logits)}\")\n",
    "            # print(\"\")\n",
    "            \n",
    "            # Margin-based ranking loss\n",
    "            # Make sure to unsqueeze dimensions for broadcasting (correct_logits: (num_correct, 1), incorrect_logits: (num_incorrect,))\n",
    "            pairwise_losses = torch.relu(self.margin + incorrect_logits.unsqueeze(0) - correct_logits.unsqueeze(1))\n",
    "            \n",
    "            # Mean pairwise loss for this example\n",
    "            loss += pairwise_losses.mean()\n",
    "\n",
    "        return loss / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank_and_top_k(predicted_indices, correct_indices, k):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Reciprocal Rank (MRR) and Top-k accuracy for the batch.\n",
    "    \n",
    "    Args:\n",
    "        predicted_indices (torch.Tensor): Tensor of shape (batch_size, num_classes) with the predicted ranks.\n",
    "        correct_indices (torch.Tensor): Tensor of shape (batch_size, num_correct) with the correct indices.\n",
    "        k (int): The top-k value for calculating Top-k accuracy.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Mean Reciprocal Rank (float), Top-k Accuracy (float) for the batch.\n",
    "    \"\"\"\n",
    "    batch_size = predicted_indices.size(0)\n",
    "    reciprocal_ranks = []\n",
    "    top_k_hits = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Get the correct indices as a set\n",
    "        correct_index_set = set(correct_indices[i].tolist())\n",
    "        \n",
    "        # Calculate Reciprocal Rank\n",
    "        for rank, idx in enumerate(predicted_indices[i].tolist(), start=1):\n",
    "            if idx in correct_index_set:\n",
    "                reciprocal_ranks.append(1.0 / rank)\n",
    "                break\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0)  # No correct index found in the predictions\n",
    "        \n",
    "        # Calculate Top-k Accuracy\n",
    "        top_k_predictions = set(predicted_indices[i, :k].tolist())\n",
    "        if correct_index_set.intersection(top_k_predictions):\n",
    "            top_k_hits += 1\n",
    "    \n",
    "    mrr = sum(reciprocal_ranks) / batch_size\n",
    "    top_k_accuracy = top_k_hits / batch_size\n",
    "    \n",
    "    return mrr, top_k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, k=10):\n",
    "    model.eval()\n",
    "    total_mrr = 0.0\n",
    "    total_top_k = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (target_formulas, padded_precursor_indexes) in enumerate(dataloader):\n",
    "            # Move data to the same device as the model\n",
    "            target_formulas = target_formulas.to(device)\n",
    "            padded_precursor_indexes = [indices.to(device) for indices in padded_precursor_indexes]\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(target_formulas)  # Shape: (batch_size, output_dim)\n",
    "\n",
    "            # Get the predicted indices sorted by logits (descending order)\n",
    "            _, predicted_indices = torch.sort(logits, descending=True)\n",
    "\n",
    "            # Calculate MRR\n",
    "            batch_mrr, batch_top_k = mean_reciprocal_rank_and_top_k(predicted_indices, torch.stack(padded_precursor_indexes), k=10)\n",
    "            total_mrr += batch_mrr\n",
    "            total_top_k += batch_top_k\n",
    "            batch_count += 1\n",
    "\n",
    "    avg_mrr = total_mrr / batch_count\n",
    "    avg_top_k = total_top_k / batch_count\n",
    "    print(f\"Evaluation Complete. Average MRR: {avg_mrr:.4f}. Average Top-{k} Accuracy: {avg_top_k:.4f}\")\n",
    "    return avg_mrr, avg_top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [1/270], Loss: 100.0063\n",
      "Epoch [1/100], Step [2/270], Loss: 100.0045\n",
      "Epoch [1/100], Step [3/270], Loss: 99.9857\n",
      "Epoch [1/100], Step [4/270], Loss: 100.0118\n",
      "Epoch [1/100], Step [5/270], Loss: 100.0049\n",
      "Epoch [1/100], Step [6/270], Loss: 100.0131\n",
      "Epoch [1/100], Step [7/270], Loss: 99.9867\n",
      "Epoch [1/100], Step [8/270], Loss: 99.9944\n",
      "Epoch [1/100], Step [9/270], Loss: 100.0014\n",
      "Epoch [1/100], Step [10/270], Loss: 99.9989\n",
      "Epoch [1/100], Step [11/270], Loss: 100.0108\n",
      "Epoch [1/100], Step [12/270], Loss: 100.0058\n",
      "Epoch [1/100], Step [13/270], Loss: 99.9873\n",
      "Epoch [1/100], Step [14/270], Loss: 99.9793\n",
      "Epoch [1/100], Step [15/270], Loss: 99.9960\n",
      "Epoch [1/100], Step [16/270], Loss: 99.9892\n",
      "Epoch [1/100], Step [17/270], Loss: 100.0048\n",
      "Epoch [1/100], Step [18/270], Loss: 99.9942\n",
      "Epoch [1/100], Step [19/270], Loss: 99.9789\n",
      "Epoch [1/100], Step [20/270], Loss: 100.0079\n",
      "Epoch [1/100], Step [21/270], Loss: 99.9863\n",
      "Epoch [1/100], Step [22/270], Loss: 99.9874\n",
      "Epoch [1/100], Step [23/270], Loss: 99.9822\n",
      "Epoch [1/100], Step [24/270], Loss: 100.0047\n",
      "Epoch [1/100], Step [25/270], Loss: 99.9895\n",
      "Epoch [1/100], Step [26/270], Loss: 99.9896\n",
      "Epoch [1/100], Step [27/270], Loss: 100.0267\n",
      "Epoch [1/100], Step [28/270], Loss: 99.9958\n",
      "Epoch [1/100], Step [29/270], Loss: 99.9955\n",
      "Epoch [1/100], Step [30/270], Loss: 99.9834\n",
      "Epoch [1/100], Step [31/270], Loss: 99.9964\n",
      "Epoch [1/100], Step [32/270], Loss: 99.9937\n",
      "Epoch [1/100], Step [33/270], Loss: 99.9726\n",
      "Epoch [1/100], Step [34/270], Loss: 99.9822\n",
      "Epoch [1/100], Step [35/270], Loss: 100.0017\n",
      "Epoch [1/100], Step [36/270], Loss: 99.9947\n",
      "Epoch [1/100], Step [37/270], Loss: 99.9967\n",
      "Epoch [1/100], Step [38/270], Loss: 100.0026\n",
      "Epoch [1/100], Step [39/270], Loss: 99.9929\n",
      "Epoch [1/100], Step [40/270], Loss: 99.9996\n",
      "Epoch [1/100], Step [41/270], Loss: 99.9964\n",
      "Epoch [1/100], Step [42/270], Loss: 99.9951\n",
      "Epoch [1/100], Step [43/270], Loss: 99.9939\n",
      "Epoch [1/100], Step [44/270], Loss: 99.9912\n",
      "Epoch [1/100], Step [45/270], Loss: 99.9852\n",
      "Epoch [1/100], Step [46/270], Loss: 99.9846\n",
      "Epoch [1/100], Step [47/270], Loss: 99.9710\n",
      "Epoch [1/100], Step [48/270], Loss: 99.9310\n",
      "Epoch [1/100], Step [49/270], Loss: 100.0032\n",
      "Epoch [1/100], Step [50/270], Loss: 99.9910\n",
      "Epoch [1/100], Step [51/270], Loss: 100.0139\n",
      "Epoch [1/100], Step [52/270], Loss: 100.0138\n",
      "Epoch [1/100], Step [53/270], Loss: 99.9939\n",
      "Epoch [1/100], Step [54/270], Loss: 99.9954\n",
      "Epoch [1/100], Step [55/270], Loss: 99.9782\n",
      "Epoch [1/100], Step [56/270], Loss: 99.9846\n",
      "Epoch [1/100], Step [57/270], Loss: 99.9856\n",
      "Epoch [1/100], Step [58/270], Loss: 99.9993\n",
      "Epoch [1/100], Step [59/270], Loss: 99.9837\n",
      "Epoch [1/100], Step [60/270], Loss: 99.9909\n",
      "Epoch [1/100], Step [61/270], Loss: 99.9950\n",
      "Epoch [1/100], Step [62/270], Loss: 99.9108\n",
      "Epoch [1/100], Step [63/270], Loss: 99.9700\n",
      "Epoch [1/100], Step [64/270], Loss: 99.9683\n",
      "Epoch [1/100], Step [65/270], Loss: 100.0131\n",
      "Epoch [1/100], Step [66/270], Loss: 100.0075\n",
      "Epoch [1/100], Step [67/270], Loss: 99.9648\n",
      "Epoch [1/100], Step [68/270], Loss: 99.9467\n",
      "Epoch [1/100], Step [69/270], Loss: 99.9340\n",
      "Epoch [1/100], Step [70/270], Loss: 99.9167\n",
      "Epoch [1/100], Step [71/270], Loss: 99.9514\n",
      "Epoch [1/100], Step [72/270], Loss: 100.0107\n",
      "Epoch [1/100], Step [73/270], Loss: 99.9798\n",
      "Epoch [1/100], Step [74/270], Loss: 99.9702\n",
      "Epoch [1/100], Step [75/270], Loss: 99.9723\n",
      "Epoch [1/100], Step [76/270], Loss: 99.9829\n",
      "Epoch [1/100], Step [77/270], Loss: 99.9712\n",
      "Epoch [1/100], Step [78/270], Loss: 99.9965\n",
      "Epoch [1/100], Step [79/270], Loss: 99.9410\n",
      "Epoch [1/100], Step [80/270], Loss: 99.9544\n",
      "Epoch [1/100], Step [81/270], Loss: 99.9470\n",
      "Epoch [1/100], Step [82/270], Loss: 99.9548\n",
      "Epoch [1/100], Step [83/270], Loss: 99.9637\n",
      "Epoch [1/100], Step [84/270], Loss: 99.9676\n",
      "Epoch [1/100], Step [85/270], Loss: 99.9724\n",
      "Epoch [1/100], Step [86/270], Loss: 99.9477\n",
      "Epoch [1/100], Step [87/270], Loss: 99.9627\n",
      "Epoch [1/100], Step [88/270], Loss: 99.9609\n",
      "Epoch [1/100], Step [89/270], Loss: 99.9404\n",
      "Epoch [1/100], Step [90/270], Loss: 99.9499\n",
      "Epoch [1/100], Step [91/270], Loss: 99.9653\n",
      "Epoch [1/100], Step [92/270], Loss: 99.9035\n",
      "Epoch [1/100], Step [93/270], Loss: 99.9886\n",
      "Epoch [1/100], Step [94/270], Loss: 99.9949\n",
      "Epoch [1/100], Step [95/270], Loss: 99.9319\n",
      "Epoch [1/100], Step [96/270], Loss: 99.8573\n",
      "Epoch [1/100], Step [97/270], Loss: 100.0247\n",
      "Epoch [1/100], Step [98/270], Loss: 99.9452\n",
      "Epoch [1/100], Step [99/270], Loss: 99.9298\n",
      "Epoch [1/100], Step [100/270], Loss: 99.8860\n",
      "Epoch [1/100], Step [101/270], Loss: 99.9853\n",
      "Epoch [1/100], Step [102/270], Loss: 99.8681\n",
      "Epoch [1/100], Step [103/270], Loss: 100.0085\n",
      "Epoch [1/100], Step [104/270], Loss: 99.7971\n",
      "Epoch [1/100], Step [105/270], Loss: 99.9136\n",
      "Epoch [1/100], Step [106/270], Loss: 99.8472\n",
      "Epoch [1/100], Step [107/270], Loss: 99.9621\n",
      "Epoch [1/100], Step [108/270], Loss: 99.8095\n",
      "Epoch [1/100], Step [109/270], Loss: 99.7178\n",
      "Epoch [1/100], Step [110/270], Loss: 99.7857\n",
      "Epoch [1/100], Step [111/270], Loss: 99.8618\n",
      "Epoch [1/100], Step [112/270], Loss: 99.8864\n",
      "Epoch [1/100], Step [113/270], Loss: 99.7841\n",
      "Epoch [1/100], Step [114/270], Loss: 99.6950\n",
      "Epoch [1/100], Step [115/270], Loss: 99.7968\n",
      "Epoch [1/100], Step [116/270], Loss: 99.7836\n",
      "Epoch [1/100], Step [117/270], Loss: 99.6072\n",
      "Epoch [1/100], Step [118/270], Loss: 100.0075\n",
      "Epoch [1/100], Step [119/270], Loss: 99.7950\n",
      "Epoch [1/100], Step [120/270], Loss: 99.7417\n",
      "Epoch [1/100], Step [121/270], Loss: 99.8994\n",
      "Epoch [1/100], Step [122/270], Loss: 99.8236\n",
      "Epoch [1/100], Step [123/270], Loss: 99.8481\n",
      "Epoch [1/100], Step [124/270], Loss: 99.9803\n",
      "Epoch [1/100], Step [125/270], Loss: 99.7432\n",
      "Epoch [1/100], Step [126/270], Loss: 99.7113\n",
      "Epoch [1/100], Step [127/270], Loss: 99.9572\n",
      "Epoch [1/100], Step [128/270], Loss: 99.6905\n",
      "Epoch [1/100], Step [129/270], Loss: 99.9726\n",
      "Epoch [1/100], Step [130/270], Loss: 99.4669\n",
      "Epoch [1/100], Step [131/270], Loss: 99.8828\n",
      "Epoch [1/100], Step [132/270], Loss: 99.4605\n",
      "Epoch [1/100], Step [133/270], Loss: 99.8872\n",
      "Epoch [1/100], Step [134/270], Loss: 99.5891\n",
      "Epoch [1/100], Step [135/270], Loss: 99.5017\n",
      "Epoch [1/100], Step [136/270], Loss: 99.1810\n",
      "Epoch [1/100], Step [137/270], Loss: 99.3707\n",
      "Epoch [1/100], Step [138/270], Loss: 99.6729\n",
      "Epoch [1/100], Step [139/270], Loss: 99.4353\n",
      "Epoch [1/100], Step [140/270], Loss: 99.2996\n",
      "Epoch [1/100], Step [141/270], Loss: 98.8768\n",
      "Epoch [1/100], Step [142/270], Loss: 99.2503\n",
      "Epoch [1/100], Step [143/270], Loss: 99.3604\n",
      "Epoch [1/100], Step [144/270], Loss: 99.5046\n",
      "Epoch [1/100], Step [145/270], Loss: 99.3379\n",
      "Epoch [1/100], Step [146/270], Loss: 98.9362\n",
      "Epoch [1/100], Step [147/270], Loss: 99.5344\n",
      "Epoch [1/100], Step [148/270], Loss: 99.5422\n",
      "Epoch [1/100], Step [149/270], Loss: 99.5421\n",
      "Epoch [1/100], Step [150/270], Loss: 98.9695\n",
      "Epoch [1/100], Step [151/270], Loss: 99.1681\n",
      "Epoch [1/100], Step [152/270], Loss: 99.3940\n",
      "Epoch [1/100], Step [153/270], Loss: 98.5190\n",
      "Epoch [1/100], Step [154/270], Loss: 98.0577\n",
      "Epoch [1/100], Step [155/270], Loss: 99.2316\n",
      "Epoch [1/100], Step [156/270], Loss: 97.1295\n",
      "Epoch [1/100], Step [157/270], Loss: 98.2391\n",
      "Epoch [1/100], Step [158/270], Loss: 98.1571\n",
      "Epoch [1/100], Step [159/270], Loss: 98.8276\n",
      "Epoch [1/100], Step [160/270], Loss: 98.0412\n",
      "Epoch [1/100], Step [161/270], Loss: 99.3435\n",
      "Epoch [1/100], Step [162/270], Loss: 99.5328\n",
      "Epoch [1/100], Step [163/270], Loss: 98.4477\n",
      "Epoch [1/100], Step [164/270], Loss: 99.1995\n",
      "Epoch [1/100], Step [165/270], Loss: 99.3946\n",
      "Epoch [1/100], Step [166/270], Loss: 99.6768\n",
      "Epoch [1/100], Step [167/270], Loss: 98.4372\n",
      "Epoch [1/100], Step [168/270], Loss: 98.5798\n",
      "Epoch [1/100], Step [169/270], Loss: 95.0263\n",
      "Epoch [1/100], Step [170/270], Loss: 97.9036\n",
      "Epoch [1/100], Step [171/270], Loss: 95.4857\n",
      "Epoch [1/100], Step [172/270], Loss: 99.7509\n",
      "Epoch [1/100], Step [173/270], Loss: 97.3350\n",
      "Epoch [1/100], Step [174/270], Loss: 96.0010\n",
      "Epoch [1/100], Step [175/270], Loss: 98.6159\n",
      "Epoch [1/100], Step [176/270], Loss: 97.6806\n",
      "Epoch [1/100], Step [177/270], Loss: 98.5475\n",
      "Epoch [1/100], Step [178/270], Loss: 94.8481\n",
      "Epoch [1/100], Step [179/270], Loss: 95.9826\n",
      "Epoch [1/100], Step [180/270], Loss: 92.8343\n",
      "Epoch [1/100], Step [181/270], Loss: 92.5351\n",
      "Epoch [1/100], Step [182/270], Loss: 99.2048\n",
      "Epoch [1/100], Step [183/270], Loss: 94.4603\n",
      "Epoch [1/100], Step [184/270], Loss: 94.8965\n",
      "Epoch [1/100], Step [185/270], Loss: 96.8463\n",
      "Epoch [1/100], Step [186/270], Loss: 92.1689\n",
      "Epoch [1/100], Step [187/270], Loss: 92.7736\n",
      "Epoch [1/100], Step [188/270], Loss: 96.4564\n",
      "Epoch [1/100], Step [189/270], Loss: 94.2839\n",
      "Epoch [1/100], Step [190/270], Loss: 89.2894\n",
      "Epoch [1/100], Step [191/270], Loss: 89.3351\n",
      "Epoch [1/100], Step [192/270], Loss: 88.9425\n",
      "Epoch [1/100], Step [193/270], Loss: 90.0361\n",
      "Epoch [1/100], Step [194/270], Loss: 88.1917\n",
      "Epoch [1/100], Step [195/270], Loss: 91.3845\n",
      "Epoch [1/100], Step [196/270], Loss: 84.4410\n",
      "Epoch [1/100], Step [197/270], Loss: 87.2121\n",
      "Epoch [1/100], Step [198/270], Loss: 96.6427\n",
      "Epoch [1/100], Step [199/270], Loss: 90.5305\n",
      "Epoch [1/100], Step [200/270], Loss: 92.4513\n",
      "Epoch [1/100], Step [201/270], Loss: 99.3885\n",
      "Epoch [1/100], Step [202/270], Loss: 78.3765\n",
      "Epoch [1/100], Step [203/270], Loss: 96.5551\n",
      "Epoch [1/100], Step [204/270], Loss: 102.9199\n",
      "Epoch [1/100], Step [205/270], Loss: 95.7260\n",
      "Epoch [1/100], Step [206/270], Loss: 95.2083\n",
      "Epoch [1/100], Step [207/270], Loss: 84.1363\n",
      "Epoch [1/100], Step [208/270], Loss: 102.9538\n",
      "Epoch [1/100], Step [209/270], Loss: 73.5754\n",
      "Epoch [1/100], Step [210/270], Loss: 83.6837\n",
      "Epoch [1/100], Step [211/270], Loss: 93.5716\n",
      "Epoch [1/100], Step [212/270], Loss: 94.2293\n",
      "Epoch [1/100], Step [213/270], Loss: 87.8309\n",
      "Epoch [1/100], Step [214/270], Loss: 85.7407\n",
      "Epoch [1/100], Step [215/270], Loss: 84.8593\n",
      "Epoch [1/100], Step [216/270], Loss: 91.7696\n",
      "Epoch [1/100], Step [217/270], Loss: 78.9771\n",
      "Epoch [1/100], Step [218/270], Loss: 83.3347\n",
      "Epoch [1/100], Step [219/270], Loss: 75.3516\n",
      "Epoch [1/100], Step [220/270], Loss: 91.8607\n",
      "Epoch [1/100], Step [221/270], Loss: 77.1189\n",
      "Epoch [1/100], Step [222/270], Loss: 88.2660\n",
      "Epoch [1/100], Step [223/270], Loss: 80.6882\n",
      "Epoch [1/100], Step [224/270], Loss: 82.8402\n",
      "Epoch [1/100], Step [225/270], Loss: 80.3835\n",
      "Epoch [1/100], Step [226/270], Loss: 64.1750\n",
      "Epoch [1/100], Step [227/270], Loss: 61.9414\n",
      "Epoch [1/100], Step [228/270], Loss: 72.6616\n",
      "Epoch [1/100], Step [229/270], Loss: 69.9052\n",
      "Epoch [1/100], Step [230/270], Loss: 75.1903\n",
      "Epoch [1/100], Step [231/270], Loss: 67.1126\n",
      "Epoch [1/100], Step [232/270], Loss: 86.8933\n",
      "Epoch [1/100], Step [233/270], Loss: 79.8754\n",
      "Epoch [1/100], Step [234/270], Loss: 76.0932\n",
      "Epoch [1/100], Step [235/270], Loss: 89.5964\n",
      "Epoch [1/100], Step [236/270], Loss: 80.1032\n",
      "Epoch [1/100], Step [237/270], Loss: 87.1525\n",
      "Epoch [1/100], Step [238/270], Loss: 81.6192\n",
      "Epoch [1/100], Step [239/270], Loss: 63.6673\n",
      "Epoch [1/100], Step [240/270], Loss: 78.3995\n",
      "Epoch [1/100], Step [241/270], Loss: 89.5959\n",
      "Epoch [1/100], Step [242/270], Loss: 81.9312\n",
      "Epoch [1/100], Step [243/270], Loss: 105.9804\n",
      "Epoch [1/100], Step [244/270], Loss: 73.2978\n",
      "Epoch [1/100], Step [245/270], Loss: 87.5042\n",
      "Epoch [1/100], Step [246/270], Loss: 76.4214\n",
      "Epoch [1/100], Step [247/270], Loss: 88.5594\n",
      "Epoch [1/100], Step [248/270], Loss: 81.0471\n",
      "Epoch [1/100], Step [249/270], Loss: 80.5662\n",
      "Epoch [1/100], Step [250/270], Loss: 81.4798\n",
      "Epoch [1/100], Step [251/270], Loss: 78.5533\n",
      "Epoch [1/100], Step [252/270], Loss: 94.9189\n",
      "Epoch [1/100], Step [253/270], Loss: 69.7852\n",
      "Epoch [1/100], Step [254/270], Loss: 58.0965\n",
      "Epoch [1/100], Step [255/270], Loss: 81.4937\n",
      "Epoch [1/100], Step [256/270], Loss: 83.3704\n",
      "Epoch [1/100], Step [257/270], Loss: 80.2891\n",
      "Epoch [1/100], Step [258/270], Loss: 77.2846\n",
      "Epoch [1/100], Step [259/270], Loss: 82.0612\n",
      "Epoch [1/100], Step [260/270], Loss: 83.2970\n",
      "Epoch [1/100], Step [261/270], Loss: 89.3430\n",
      "Epoch [1/100], Step [262/270], Loss: 81.6316\n",
      "Epoch [1/100], Step [263/270], Loss: 49.9561\n",
      "Epoch [1/100], Step [264/270], Loss: 83.6803\n",
      "Epoch [1/100], Step [265/270], Loss: 84.6283\n",
      "Epoch [1/100], Step [266/270], Loss: 87.1944\n",
      "Epoch [1/100], Step [267/270], Loss: 99.7067\n",
      "Epoch [1/100], Step [268/270], Loss: 86.0083\n",
      "Epoch [1/100], Step [269/270], Loss: 61.2825\n",
      "Epoch [1/100], Step [270/270], Loss: 97.2827\n",
      "Epoch [1/100] Complete. Average Loss: 94.5937\n",
      "Evaluation Complete. Average MRR: 0.0104. Average Top-10 Accuracy: 0.0184\n",
      "Epoch [2/100], Step [1/270], Loss: 27.9784\n",
      "Epoch [2/100], Step [2/270], Loss: 27.5043\n",
      "Epoch [2/100], Step [3/270], Loss: 17.5353\n",
      "Epoch [2/100], Step [4/270], Loss: 19.1240\n",
      "Epoch [2/100], Step [5/270], Loss: 13.1142\n",
      "Epoch [2/100], Step [6/270], Loss: 12.0716\n",
      "Epoch [2/100], Step [7/270], Loss: 30.4456\n",
      "Epoch [2/100], Step [8/270], Loss: 17.7224\n",
      "Epoch [2/100], Step [9/270], Loss: 26.2153\n",
      "Epoch [2/100], Step [10/270], Loss: 14.4142\n",
      "Epoch [2/100], Step [11/270], Loss: 30.4069\n",
      "Epoch [2/100], Step [12/270], Loss: 19.3541\n",
      "Epoch [2/100], Step [13/270], Loss: 19.1456\n",
      "Epoch [2/100], Step [14/270], Loss: 16.5775\n",
      "Epoch [2/100], Step [15/270], Loss: 23.7200\n",
      "Epoch [2/100], Step [16/270], Loss: 20.6529\n",
      "Epoch [2/100], Step [17/270], Loss: 14.2076\n",
      "Epoch [2/100], Step [18/270], Loss: 19.0670\n",
      "Epoch [2/100], Step [19/270], Loss: 23.1380\n",
      "Epoch [2/100], Step [20/270], Loss: 24.5497\n",
      "Epoch [2/100], Step [21/270], Loss: 23.5376\n",
      "Epoch [2/100], Step [22/270], Loss: 19.8992\n",
      "Epoch [2/100], Step [23/270], Loss: 14.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:130] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     53\u001b[0m batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/msm/lib/python3.12/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/msm/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/msm/lib/python3.12/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[1;32m    169\u001b[0m         exp_avgs,\n\u001b[1;32m    170\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    172\u001b[0m         state_steps,\n\u001b[1;32m    173\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    175\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    176\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    177\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/msm/lib/python3.12/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m func(params,\n\u001b[1;32m    317\u001b[0m      grads,\n\u001b[1;32m    318\u001b[0m      exp_avgs,\n\u001b[1;32m    319\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    321\u001b[0m      state_steps,\n\u001b[1;32m    322\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    323\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    324\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    325\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    326\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    327\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    328\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    329\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    330\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    331\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    332\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    333\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/miniconda3/envs/msm/lib/python3.12/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop parameters\n",
    "num_epochs = 100\n",
    "log_interval = 1\n",
    "save_interval = 1000\n",
    "eval_interval = 1\n",
    "\n",
    "checkpoints_dir = \"checkpoints2\"\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "dataset = TrainDataset()\n",
    "\n",
    "# Split dataset into 80% train and 20% evaluate\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=train_collate_fn)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=16, shuffle=False, collate_fn=train_collate_fn)\n",
    "\n",
    "model = SynthesisPredictionModel()\n",
    "\n",
    "# Define optimizer and custom loss function\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = CustomRankLoss(margin=100.0)\n",
    "\n",
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for batch_idx, (target_formulas, padded_precursor_indexes) in enumerate(train_dataloader):\n",
    "        # Move data to the same device as the model\n",
    "        target_formulas = target_formulas.to(device)\n",
    "        padded_precursor_indexes = [indices.to(device) for indices in padded_precursor_indexes]\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(target_formulas)  # Shape: (batch_size, output_dim)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, padded_precursor_indexes)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / batch_count\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Complete. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate the model on the eval set every eval_interval epochs\n",
    "    if (epoch + 1) % eval_interval == 0:\n",
    "        evaluate_model(model, eval_dataloader, device)\n",
    "\n",
    "    # Save the model checkpoint every save_interval epochs\n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoints_dir, f\"model_epoch_{epoch + 1}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Model saved to {checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
